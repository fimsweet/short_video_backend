# ============================================
# DOCKER COMPOSE - PRODUCTION (AWS)
# ============================================
# This file is for reference when deploying to AWS
# In production, use AWS managed services instead of containers
# ============================================

version: '3.8'

services:
  # ============================================
  # USER SERVICE
  # ============================================
  user-service:
    build:
      context: ./user-service
      dockerfile: Dockerfile
    container_name: user-service
    restart: always
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - PORT=3000
      # Database (AWS RDS)
      - DB_HOST=${DB_HOST}
      - DB_PORT=${DB_PORT}
      - DB_USERNAME=${DB_USERNAME}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_NAME=${DB_NAME}
      # Redis (AWS ElastiCache)
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      # JWT
      - JWT_SECRET=${JWT_SECRET}
      - JWT_EXPIRATION=${JWT_EXPIRATION}
      # AWS S3
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
      - AWS_S3_BUCKET=${AWS_S3_BUCKET}
      - CLOUDFRONT_URL=${CLOUDFRONT_URL}
      # Google OAuth
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      # Email
      - EMAIL_USER=${EMAIL_USER}
      - EMAIL_APP_PASSWORD=${EMAIL_APP_PASSWORD}
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - backend-network

  # ============================================
  # VIDEO SERVICE
  # ============================================
  video-service:
    build:
      context: ./video-service
      dockerfile: Dockerfile
    container_name: video-service
    restart: always
    ports:
      - "3002:3002"
    environment:
      - NODE_ENV=production
      - PORT=3002
      # Database (AWS RDS)
      - DB_HOST=${DB_HOST}
      - DB_PORT=${DB_PORT}
      - DB_USERNAME=${DB_USERNAME}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_DATABASE=${DB_NAME}
      # Redis (AWS ElastiCache)
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      # RabbitMQ / SQS
      - RABBITMQ_URL=${RABBITMQ_URL}
      - RABBITMQ_QUEUE=${RABBITMQ_QUEUE}
      - USE_SQS=${USE_SQS}
      - AWS_SQS_QUEUE_URL=${AWS_SQS_QUEUE_URL}
      # Elasticsearch (AWS OpenSearch)
      - ELASTICSEARCH_NODE=${ELASTICSEARCH_NODE}
      # AWS S3
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
      - AWS_S3_BUCKET=${AWS_S3_BUCKET}
      - CLOUDFRONT_URL=${CLOUDFRONT_URL}
      # User Service
      - USER_SERVICE_URL=http://user-service:3000
    depends_on:
      - user-service
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - backend-network

  # ============================================
  # VIDEO WORKER SERVICE
  # ============================================
  video-worker:
    build:
      context: ./video-worker-service
      dockerfile: Dockerfile
    container_name: video-worker
    restart: always
    # No ports - this is a background worker
    environment:
      - NODE_ENV=production
      # Database (AWS RDS)
      - DB_HOST=${DB_HOST}
      - DB_PORT=${DB_PORT}
      - DB_USERNAME=${DB_USERNAME}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_DATABASE=${DB_NAME}
      # RabbitMQ / SQS
      - RABBITMQ_URL=${RABBITMQ_URL}
      - RABBITMQ_QUEUE=${RABBITMQ_QUEUE}
      - USE_SQS=${USE_SQS}
      - AWS_SQS_QUEUE_URL=${AWS_SQS_QUEUE_URL}
      # ============================================
      # ‚ö†Ô∏è WORKER CONCURRENCY - CRITICAL FOR SCALING
      # ============================================
      # FFmpeg is CPU-bound. Do NOT increase this!
      # - Setting WORKER_CONCURRENCY=1 means 1 video/container
      # - Scale by increasing replicas, not concurrency
      # - Multiple FFmpeg processes = context switching overhead
      # ============================================
      - WORKER_CONCURRENCY=1
      # ============================================
      # üê≥ SHARED VOLUME PATH
      # ============================================
      # For S3-first workflow: Worker downloads from S3 directly
      # For shared volume: Set to the mount point path
      # ============================================
      - UPLOAD_ROOT_PATH=/app/uploads
      # AWS S3
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
      - AWS_S3_BUCKET=${AWS_S3_BUCKET}
      - CLOUDFRONT_URL=${CLOUDFRONT_URL}
      # Video Service
      - VIDEO_SERVICE_URL=http://video-service:3002
    depends_on:
      - video-service
    networks:
      - backend-network
    # Scale workers based on load
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 2G

networks:
  backend-network:
    driver: bridge
